{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def pickle_it(obj, name_str):\n",
    "    '''\n",
    "\n",
    "    Create a pickle file in the current working directory\n",
    "    and store a pickle file by the name '<name_str>.pickle'\n",
    "    with the object serialized in it\n",
    "\n",
    "    '''\n",
    "    file_name = name_str + '.pickle'\n",
    "\n",
    "    with open(file_name, 'wb') as pickle_out:\n",
    "        pickle.dump(obj, pickle_out)\n",
    "        pickle_out.close()\n",
    "    \n",
    "\n",
    "def read_pickle(name_str):\n",
    "    '''\n",
    "\n",
    "    Read the pickle file named '<name_str>.pickle' to\n",
    "    deserialize the previously serialized object and return\n",
    "    it\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "    \tfile_name = name_str + '.pickle'\n",
    "    \tobj = None\n",
    "\n",
    "    \twith open(file_name, 'rb') as pickle_in:\n",
    "    \t\tobj = pickle.load(pickle_in)\n",
    "\n",
    "    except:\n",
    "    \tfile_name = name_str\n",
    "    \tobj = None\n",
    "\n",
    "    \twith open(file_name, 'rb') as pickle_in:\n",
    "    \t\tobj = pickle.load(pickle_in, encoding = 'bytes')\n",
    "\n",
    "    finally:\n",
    "    \tfile_name = name_str\n",
    "    \tobj = None\n",
    "\n",
    "    \twith open(file_name, 'rb') as pickle_in:\n",
    "    \t\tobj = pickle.load(pickle_in, encoding = 'bytes')\n",
    "\n",
    "    return obj\t\n",
    "\n",
    "\n",
    "def main():\n",
    "\tpass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fbaa4491cf3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprocess_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'data_loader'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from data_loader import *\n",
    "\n",
    "def process_batches(data_dict, num_batches = 5):\n",
    "\n",
    "\t\"\"\"\n",
    "\tParams:\n",
    "\t\tdata_dict: python_dict containing batches of data under key 'batch_i' (ith batch)\n",
    "\t\t\t\t   Each batch is a dictionary with the actual CIFAR-10 image data\n",
    "\t\t\t\t   under key b'data':-\n",
    "\t\t\tdata_dict['batch_i'][b'data] -- a 10000x3072 numpy array of uint8s. \n",
    "\t\t\tEach row of the array stores a 32x32 colour image. \n",
    "\t\t\tThe first 1024 entries contain the red channel values, \n",
    "\t\t\tthe next 1024 the green, and the final 1024 the blue. \n",
    "\t\t\tThe image is stored in row-major order, so that the first\n",
    "\t\t\t32 entries of the array are the red channel values of the first row of the image.\n",
    "\n",
    "\t\tnum_batches: int stating number of batches of data in data_dict. Defaults to 5. \n",
    "\n",
    "\tReturns:\n",
    "\t\tprocessed_dict: python_dict containing batches of data under key 'batch_i' (ith batch)\n",
    "\t\t\t\t\t\tEach batch is a numpy ndarray of shape = (10000, 32, 32, 3) with \n",
    "\t\t\t\t\t\tactual CIFAR-10 image data, formated in \"NHWC\" format, suitable being \n",
    "\t\t\t\t\t\tfed into a CNN.\n",
    "\t\"\"\"\n",
    "\n",
    "\tprocessed_dict= {}\n",
    "\tfor i in range(1, num_batches + 1):\n",
    "\t\tx = data_dict[\"batch_\" + str(i)][b'data']\n",
    "\t\tnum_eg = data_dict[\"batch_\" + str(i)][b'data'].shape[0]\n",
    "\t\tx = x.reshape((num_eg, 32, 32, 3), order = 'F')\n",
    "\t\tx = np.rot90(x, -1, (1, 2))\n",
    "\t\tprocessed_dict[\"batch_\" + str(i)] = x\n",
    "\n",
    "\treturn processed_dict\n",
    "\n",
    "def vec2img(vec):\n",
    "\t\"\"\"\n",
    "\tConverts vector to rgb image while preserving the 'num_examples' dimension.\n",
    "\tAssumes the first dimension to be the 'num_batches' dimension.\n",
    "\t\"\"\"\n",
    "\n",
    "\tnum_eg = vec.shape[0]\n",
    "\timg = vec.reshape((num_eg, 32, 32, 3), order = 'F')\n",
    "\timg = np.rot90(img, -1, (1, 2))\n",
    "\n",
    "\treturn img\n",
    "\n",
    "def process_test_labels(test_data_orig_dict):\n",
    "\treturn test_data_orig_dict[b'labels']\n",
    "\n",
    "\n",
    "def process_labels(data_dict, num_batches = 5):\n",
    "\t\"\"\"\n",
    "\tParams:\n",
    "\t\tdata_dict: python_dict containing batches of labels under key 'batch_i' (ith batch)\n",
    "\t\t\t\t   Each batch is a dictionary with the actual CIFAR-10 image labels\n",
    "\t\t\t\t   under key b'labels':-\n",
    "\t\t\tdata_dict['batch_i'][b'labels'] -- a 10000x1 numpy array of uint8s. \n",
    "\t\t\tEach row of the array stores a label from 0 to 9 (inclusive) denoting the image category. \n",
    "\t\t\t\n",
    "\n",
    "\t\tnum_batches: int stating number of batches of data in data_dict. Defaults to 5. \n",
    "\n",
    "\tReturns:\n",
    "\t\tprocessed_dict: python_dict containing batches of labels under key 'batch_i' (ith batch)\n",
    "\t\t\t\t\t\tEach batch is a numpy ndarray of shape = (10000) with the actual\n",
    "\t\t\t\t\t\tCIFAR-10 image labels from 0 to 9 (inclusive) denoting the image category.\n",
    "\t\"\"\"\n",
    "\n",
    "\tprocessed_dict= {}\n",
    "\n",
    "\tfor i in range(1, num_batches + 1):\n",
    "\t\ty = data_dict[\"batch_\" + str(i)][b'labels']\n",
    "\t\tshape = len(data_dict[\"batch_\" + str(i)][b'labels'])\n",
    "\t\ty = np.array(y, dtype = np.int32).reshape((shape))\n",
    "\t\tprocessed_dict[\"batch_\" + str(i)] = y\n",
    "\n",
    "\treturn processed_dict\n",
    "\n",
    "def generate_one_hot(labels, num_classes):\n",
    "\tone_hot_tensor = tf.one_hot(indices = labels, depth = num_classes, axis = -1)\n",
    "\treturn one_hot_tensor\n",
    "\n",
    "def data_normalizer(data, normalizer = \"for_rgb_image\"):\n",
    "\tif normalizer == \"for_rgb_image\":\n",
    "\t\treturn data / 255.\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\ttrain_data_orig = load_training_batches()\n",
    "\tbatch = \"batch_1\"\n",
    "\teg_no = 0\n",
    "\tx = process_batches(train_data_orig)\n",
    "\tX = x[batch]\n",
    "\ty = process_labels(train_data_orig)\n",
    "\tY = y[batch]\n",
    "\tone_hot = generate_one_hot(Y, 10)\n",
    "\n",
    "\twith tf.Session() as sess:\n",
    "\t\ttf.global_variables_initializer()\n",
    "\t\tprint(one_hot.shape)\n",
    "\t\tprint(sess.run(one_hot[0:5]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dlenv)",
   "language": "python",
   "name": "dlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
